{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beat Tracking | Machine Learning .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMzUqeiv5MVP"
      },
      "source": [
        "## Loading Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1Gzzenw23DO",
        "outputId": "4a17b5b7-5661-41a5-92fe-25a080342997"
      },
      "source": [
        "!pip install import_ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp37-none-any.whl size=2976 sha256=f4d15acfc3c58e998d396ee2de228e1f31480966cf6430a73b8f6d4f319c8544\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTL1fI6XZxEt"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import librosa\n",
        "\n",
        "\n",
        "import progressbar\n",
        "import random\n",
        "import import_ipynb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAzH7uuyeRtw",
        "outputId": "8a8afb14-8f04-4f0a-dc6e-b396956e5e3e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9oGCC7OlCAC"
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
        "\n",
        "\n",
        "FPS = 100\n",
        "ONSET_PATH = '/content/gdrive/My Drive/randomsample/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP8V7bbrzs-f"
      },
      "source": [
        "class Dataset(object):\n",
        "    \n",
        "    def __init__(self, path, audio_suffix='.wav', annotation_suffix='.onsets'):\n",
        "        \n",
        "        self.path = path\n",
        "        # populate lists containing audio and annotation files\n",
        "        audio_files = madmom.utils.search_files(self.path + 'audio', audio_suffix)\n",
        "        annotation_files = madmom.utils.search_files(self.path + '/annotations', annotation_suffix, recursion_depth=1)\n",
        "        \n",
        "        # match annotation to audio files\n",
        "        self.files = []   #name \n",
        "        self.audio_files = []   # name of audios location\n",
        "        self.annotation_files = []   # location of annotation files\n",
        "        self.ind=[]   # [0,1,2,3,4...]   indexes\n",
        "        k=0\n",
        "        for annotation_file in annotation_files:           \n",
        "            # search matching audio file\n",
        "            matches = madmom.utils.match_file(annotation_file, audio_files, suffix=annotation_suffix, match_suffix=audio_suffix)\n",
        "            if len(matches) == 1:\n",
        "                audio_file = matches[0]\n",
        "                self.audio_files.append(audio_file)                   \n",
        "                self.annotation_files.append(annotation_file)\n",
        "                self.ind.append(k)\n",
        "                k=k+1\n",
        "                # save the base name\n",
        "                self.files.append(os.path.basename(annotation_file[:-len(annotation_suffix)]))\n",
        "            else:\n",
        "                warnings.warn('skipping %s, no audio file found' % annotation_file)\n",
        "        print (self.annotation_files) \n",
        "        random.shuffle(self.ind)    #shuffling index\n",
        "        self.ind=np.array(self.ind)      \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-vQbeyB5dcI"
      },
      "source": [
        "### Loading Processed Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqnwSxN5-PwX"
      },
      "source": [
        "with open('/content/gdrive/My Drive/onset_db.pkl', 'rb') as f:\n",
        "    onsets_db = pickle.load(f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9aiHM-P7T1z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjZL55eY8fZd"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataSequence(Sequence):\n",
        "    \n",
        "    mask_value = -999  # only needed for batch sizes > 1\n",
        "\n",
        "    def __init__(self, x, y, batch_size=1, max_seq_length=None, fps=FPS):\n",
        "        self.x = x\n",
        "        self.y = [madmom.utils.quantize_events(o, fps=fps, length=len(d))\n",
        "                  for o, d in zip(y, self.x)]\n",
        "        self.batch_size = batch_size\n",
        "        # print(self.batch_size)\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # determine which sequence(s) to use\n",
        "        x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        # pad them if needed\n",
        "        if self.batch_size > 1:\n",
        "            x = keras.preprocessing.sequence.pad_sequences(\n",
        "                x, maxlen=self.max_seq_length, dtype=np.float32, truncating='post', value=self.mask_value)\n",
        "            y = keras.preprocessing.sequence.pad_sequences(\n",
        "                y, maxlen=self.max_seq_length, dtype=np.int32, truncating='post', value=self.mask_value)\n",
        "        return np.array(x), np.array(y)[..., np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoE0Loyt8s6O"
      },
      "source": [
        "basedir = 'models/onsets/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRnWpAG0GFj1",
        "outputId": "d008ad6c-5cb7-46cb-b195-113319e2bf37"
      },
      "source": [
        "lr = 0.01\n",
        "print(onsets_db.ind)\n",
        "print(onsets_db.train)\n",
        "print(onsets_db.val)\n",
        "print(onsets_db.test)\n",
        "train = DataSequence([onsets_db.x[i] for i in onsets_db.train],\n",
        "                     [onsets_db.annotations[i] for i in onsets_db.train],\n",
        "                      batch_size=1, max_seq_length=60 * FPS)\n",
        "                             \n",
        "val = DataSequence([onsets_db.x[i] for i in onsets_db.val],\n",
        "                   [onsets_db.annotations[i] for i in onsets_db.val],\n",
        "                    batch_size=1, max_seq_length=60 * FPS)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[197  69 412 444 191 151 126 179 233  37 137 100 364 426 132 114 360 476\n",
            " 474 437  23 139 116 404 164  53  25 368 465 187 276  59 248  21 375 348\n",
            " 334 281  73 323  71 366 260 321 283 409  79 190  19 211 193 274 419 290\n",
            " 168 308 367 445   5 347 216  99 236 292  31 225 146 256 235 449  65 381\n",
            "  22 372  50   3 261 241 189 159 282 425  35 433 207 387 119 335  26  42\n",
            " 329  20  64 153 407 112 222 316 304 286  84 230 370 128 406 384 319 102\n",
            " 432  41 353 359 262 257  74  75 416  49 106  30 202 302  55 217  83 346\n",
            " 395 399   7 229  45  67 460  80 455  78  38 109  33  40 439 450 472 243\n",
            "  36 376  32 258 342 447 457 194 242 184 354 199 280 313 138  92 471 134\n",
            " 212 303 358 420 446 206 268 273 414 339 272 269 325 461 101 178 270  44\n",
            " 470 228 220 355 314 267 284 459 351 400 115 410 397 380 396 393 245 305\n",
            " 204 300  62 124 123 173   2 149 361  29 391  91 251 259  89 110 451 266\n",
            " 464 333 154 278 392 129 365 443 297 105  10 440 265 186 417 104 401 462\n",
            " 307 160 477 176 158 311 279  97  85 144 327 122  51 166  95 224 285 201\n",
            "   9 175 172 121 150 430 454 356 253 167   1 294 475 306 332 203 379 247\n",
            " 434 171 331 162 298  11 142 338 293 163 237 320 402 299 424 271 427 468\n",
            " 369 136  76 141  17 249  24  61 337  57 326 113 291 232 390 180  39 157\n",
            " 156 324 385 423 240 336 317 386 252 145 301 195 182  87 394 315 221 413\n",
            "  68 343 309 431  96 415 117 209 350 289  52 310 111 345 133 374 118 231\n",
            " 478 214  34 275  66 448  14 438 469 255 373 296 344 383  93 254 135 250\n",
            " 107  72 103  98 108   4 466 277 226 452 140 148 219  60 198 130  56 388\n",
            " 378 422 458 223 481 389 161 263 200 349 295  18  81 244  82 436 479  16\n",
            " 288 435  28 287 330 318  90 238 185 453 382   0  58 155 408  94  88 127\n",
            " 421 174 429 363 181 480 341  47 205 371 463 239 473 405 411  70 165  77\n",
            " 208 428 418  63 398 340  48 147 357  46  43 352 125  27 246 131 183 442\n",
            " 152 169 188 196   6 143 312 227  12 218 210 328 192 441 215 177 456 120\n",
            "  54 264 362 234 170  13 467 403 213  15 322   8  86 377]\n",
            "[197  69 412 444 191 151 126 179 233  37 137 100 364 426 132 114 360 476\n",
            " 474 437  23 139 116 404 164  53  25 368 465 187 276  59 248  21 375 348\n",
            " 334 281  73 323  71 366 260 321 283 409  79 190  19 211 193 274 419 290\n",
            " 168 308 367 445   5 347 216  99 236 292  31 225 146 256 235 449  65 381\n",
            "  22 372  50   3 261 241 189 159 282 425  35 433 207 387 119 335  26  42\n",
            " 329  20  64 153 407 112 222 316 304 286  84 230 370 128 406 384 319 102\n",
            " 432  41 353 359 262 257  74  75 416  49 106  30 202 302  55 217  83 346\n",
            " 395 399   7 229  45  67 460  80 455  78  38 109  33  40 439 450 472 243\n",
            "  36 376  32 258 342 447 457 194 242 184 354 199 280 313 138  92 471 134\n",
            " 212 303 358 420 446 206 268 273 414 339 272 269 325 461 101 178 270  44\n",
            " 470 228 220 355 314 267 284 459 351 400 115 410 397 380 396 393 245 305\n",
            " 204 300  62 124 123 173   2 149 361  29 391  91 251 259  89 110 451 266\n",
            " 464 333 154 278 392 129 365 443 297 105  10 440 265 186 417 104 401 462\n",
            " 307 160 477 176 158 311 279  97  85 144 327 122  51 166  95 224 285 201\n",
            "   9 175 172 121 150 430 454 356 253 167   1 294 475 306 332 203 379 247\n",
            " 434 171 331 162 298  11 142 338 293 163 237 320 402 299 424 271 427 468\n",
            " 369 136  76 141  17 249  24  61 337  57 326 113 291 232 390 180  39 157\n",
            " 156 324 385 423 240 336 317 386 252 145 301 195 182  87 394 315 221 413\n",
            "  68 343 309 431  96 415 117 209 350 289  52 310 111 345 133 374 118 231\n",
            " 478 214  34 275  66 448  14 438 469 255 373 296 344 383  93 254 135 250\n",
            " 107]\n",
            "[ 72 103  98 108   4 466 277 226 452 140 148 219  60 198 130  56 388 378\n",
            " 422 458 223 481 389 161 263 200 349 295  18  81 244  82 436 479  16 288\n",
            " 435  28 287 330 318  90 238 185 453 382   0  58 155 408  94  88 127 421\n",
            " 174 429 363 181 480 341  47 205 371 463 239 473 405 411  70 165  77 208\n",
            " 428 418  63 398 340  48 147 357  46  43 352 125  27 246 131 183 442 152\n",
            " 169 188 196   6 143 312 227  12 218 210 328 192 441 215 177 456 120  54\n",
            " 264 362 234 170  13 467 403 213  15 322   8  86 377]\n",
            "[ 72 103  98 108   4 466 277 226 452 140 148 219  60 198 130  56 388 378\n",
            " 422 458 223 481 389 161 263 200 349 295  18  81 244  82 436 479  16 288\n",
            " 435  28 287 330 318  90 238 185 453 382   0  58 155 408  94  88 127 421\n",
            " 174 429 363 181 480 341  47 205 371 463 239 473 405 411  70 165  77 208\n",
            " 428 418  63 398 340  48 147 357  46  43 352 125  27 246 131 183 442 152\n",
            " 169 188 196   6 143 312 227  12 218 210 328 192 441 215 177 456 120  54\n",
            " 264 362 234 170  13 467 403 213  15 322   8  86 377]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH_7Pd1kHlZr"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow. keras import Sequential\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, Bidirectional, Masking, LSTM, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLOP8JlhHnv1",
        "outputId": "d211bfff-b674-4267-853a-9a1be194c8b1"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Masking(input_shape=(None, train[0][0].shape[-1]), mask_value=train.mask_value))\n",
        "model.add(Bidirectional(SimpleRNN(units=25, return_sequences=True)))\n",
        "model.add(Bidirectional(SimpleRNN(units=25, return_sequences=True)))\n",
        "model.add(Bidirectional(SimpleRNN(units=25, return_sequences=True)))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(lr=lr, clipvalue=5, momentum=0.9),\n",
        "              metrics=['binary_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qGbgwsYHqjm",
        "outputId": "6879fa6d-e611-429d-8be5-cc9d427525bb"
      },
      "source": [
        "verbose=0\n",
        "name = '%s/lr_%s/fold_%s/' % (basedir, str(lr).replace('.', ''), str(0))\n",
        "\n",
        "mca = keras.callbacks.ModelCheckpoint(name + 'model_{epoch:02d}.h5', monitor='loss', save_best_only=False, verbose=verbose)\n",
        "mcb = keras.callbacks.ModelCheckpoint(name + 'model_best.h5', monitor='loss', save_best_only=True, verbose=verbose)\n",
        "mcv = keras.callbacks.ModelCheckpoint(name + 'model_best_val.h5', monitor='val_loss', save_best_only=True, verbose=verbose)\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=20, verbose=verbose)\n",
        "tb = keras.callbacks.TensorBoard(log_dir=name + 'logs', write_graph=True, write_images=True)\n",
        "\n",
        "print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models/onsets//lr_001/fold_0/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcoRSw7MHw_M",
        "outputId": "8a4f7b16-4add-4d42-f4a9-044878d1754c"
      },
      "source": [
        "history = model.fit_generator(train, steps_per_epoch=len(train), epochs=2, shuffle=True,\n",
        "                              validation_data=val, validation_steps=len(val),\n",
        "                              callbacks=[mca, mcb, mcv, es, tb])\n",
        "\n",
        "model.save(name + 'model_final.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "361/361 [==============================] - 272s 755ms/step - loss: 0.0159 - binary_accuracy: 0.9957 - val_loss: 0.0141 - val_binary_accuracy: 0.9970\n",
            "Epoch 2/2\n",
            "361/361 [==============================] - 273s 757ms/step - loss: 0.0115 - binary_accuracy: 0.9969 - val_loss: 0.0108 - val_binary_accuracy: 0.9976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY0OXeaoHzha"
      },
      "source": [
        "\n",
        "outdir = basedir + 'lr_%s_predictions/' % str(lr).replace('.', '')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSLuAcCrH6kC"
      },
      "source": [
        "rnn_peak_picking = madmom.features.onsets.OnsetPeakPickingProcessor(\n",
        "        threshold=0.35, pre_max=0.001, post_max=0.001, smooth=0.07,combine=0.03,fps=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6OM49UryYDp"
      },
      "source": [
        "from madmom.processors import ParallelProcessor, SequentialProcessor\n",
        "from madmom.audio.signal import SignalProcessor, FramedSignalProcessor\n",
        "from madmom.audio.stft import ShortTimeFourierTransformProcessor\n",
        "from madmom.audio.spectrogram import FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor, SpectrogramDifferenceProcessor\n",
        "        \n",
        "# define pre-processor\n",
        "class OnsetPreProcessor(SequentialProcessor):\n",
        "\n",
        "    def __init__(self, frame_sizes=[1024, 2048, 4096], num_bands=[3, 6, 12]):\n",
        "        # resample to a fixed sample rate in order to get always the same number of filter bins\n",
        "        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n",
        "        # process multi-resolution spec & diff in parallel\n",
        "        multi = ParallelProcessor([])\n",
        "        for frame_size, num_bands in zip(frame_sizes, num_bands):\n",
        "            # split audio signal in overlapping frames\n",
        "            frames = FramedSignalProcessor(frame_size=frame_size)\n",
        "            # compute STFT\n",
        "            stft = ShortTimeFourierTransformProcessor()\n",
        "            # filter the magnitudes\n",
        "            filt = FilteredSpectrogramProcessor(num_bands=num_bands)\n",
        "            # scale them logarithmically\n",
        "            spec = LogarithmicSpectrogramProcessor()\n",
        "            # stack positive differences\n",
        "            diff = SpectrogramDifferenceProcessor(positive_diffs=True, stack_diffs=np.hstack)\n",
        "            # process each frame size with spec and diff sequentially\n",
        "            multi.append(SequentialProcessor((frames, stft, filt, spec, diff)))\n",
        "        # instantiate a SequentialProcessor\n",
        "        super(OnsetPreProcessor, self).__init__((sig, multi, np.hstack))\n",
        "\n",
        "# create a callable pre-processor\n",
        "pp = OnsetPreProcessor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdRGSLO2XBCN",
        "outputId": "437262c3-055f-4226-cc11-b15c8b81b1b1"
      },
      "source": [
        "data=pp('/content/gdrive/My Drive/randomsample/audio/mridanga16_60bpm.wav')\n",
        "\n",
        "print(data.shape)\n",
        "print(model.predict(data[np.newaxis, ...]).squeeze().shape)\n",
        "act = model.predict(data[np.newaxis, ...]).squeeze()\n",
        "print(act)\n",
        "det = rnn_peak_picking(act)\n",
        "print(det)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1600, 314)\n",
            "(1600,)\n",
            "[9.6011579e-01 2.1688700e-02 2.5497973e-02 ... 4.2873621e-04 4.1359663e-04\n",
            " 2.1741688e-03]\n",
            "[ 0.    1.49  1.99  2.99  3.99  4.99  5.99  6.99  7.99 10.99 11.99 12.99\n",
            " 13.49 13.99 14.49 14.99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEE8LVjtH9HO"
      },
      "source": [
        "def evaluate_onsets(predictions, annotations, verbose=False, ann_suffix='.onsets', det_suffix='.onsets.txt'):\n",
        "    evals = []\n",
        "    for ann in annotations:\n",
        "        name = os.path.basename(ann)\n",
        "        # get the matching detection files\n",
        "        matches = madmom.utils.match_file(ann, detections, ann_suffix, det_suffix)\n",
        "        if len(matches) == 1:\n",
        "            det = madmom.io.load_onsets(matches[0])\n",
        "            ann = madmom.io.load_onsets(ann)\n",
        "            e = madmom.evaluation.onsets.OnsetEvaluation(\n",
        "                det, ann, combine=0.03, window=0.025, name=name)\n",
        "            evals.append(e)\n",
        "        if verbose:\n",
        "            print(e)\n",
        "    se = madmom.evaluation.onsets.OnsetSumEvaluation(evals)\n",
        "    me = madmom.evaluation.onsets.OnsetMeanEvaluation(evals)\n",
        "    return se, me"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M86-9g_dIBkx"
      },
      "source": [
        "detections = madmom.utils.search_files(outdir, '.onsets.txt')\n",
        "annotations = madmom.utils.search_files(ONSET_PATH + '/annotations', '.onsets')\n",
        "\n",
        "se, me = evaluate_onsets(detections, annotations)\n",
        "print(se)\n",
        "print(me)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt8bF4rqIEjT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}